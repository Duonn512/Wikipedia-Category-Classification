{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7948773,"sourceType":"datasetVersion","datasetId":4631246}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoModel, AutoTokenizer\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/wiki-data2/train_wiki_data.csv',encoding='utf-8', delimiter=',')\ntest_data = pd.read_csv('/kaggle/input/wiki-data2/test_wiki_data.csv',encoding='utf-8', delimiter=',')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport nltk\nfrom stop_words import get_stop_words\n\nnltk.download('stopwords')\nstop_words = get_stop_words('vi')\n\ndef preprocess_text(text):\n    text = re.sub(r'\\[\\d+\\]', '', text)\n    text = re.sub(r'\\([^()]*\\)', '', text)\n    text = re.sub(r'\\xa0', ' ',text)\n#     words = text.split()\n#     filtered_words = [word for word in words if word.lower() not in stop_words]\n#     filtered_text = ' '.join(filtered_words)\n    return text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['content'] = train_data['content'].apply(preprocess_text)\ntest_data['content'] = test_data['content'].apply(preprocess_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_samples_to_remove = 600\nindices_to_remove = train_data[train_data['label'] == 0].sample(n=num_samples_to_remove, random_state=42).index\ntrain_data = train_data.drop(indices_to_remove)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['label'].isnull().value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data['content']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_data[\"content\"]))\nprint(len(train_data[\"label\"]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data[\"content\"].isnull().sum())\nprint(train_data[\"label\"].isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training parameters\nMAX_LEN = 256\nBATCH_SIZE = 8\nEPOCHS = 20\nLEARNING_RATE = 0.001","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        content = str(self.data.loc[index, 'content'])\n        label = self.data.loc[index, 'label']\n        \n        encoding = self.tokenizer.encode_plus(\n            content,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'content': content,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)\n        }\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"ThuyNT03/xlm-roberta-base-VietNam-train\")\nmodel = AutoModel.from_pretrained(\"ThuyNT03/xlm-roberta-base-VietNam-train\")\nmodel.config.hidden_size = 80\n# Move model to GPU\nmodel.to(device)\nprint(model.config.hidden_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define additional layers for classification\nreduce_dim_layer = nn.Linear(768, 80)\nclass Classifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(Classifier, self).__init__()\n        self.reduce_dim_layer = nn.Linear(768, 80)\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(0.2)\n        \n    def forward(self, x):\n        x = self.reduce_dim_layer(x)\n        x = self.dropout(torch.relu(self.fc1(x)))\n        x = self.fc2(x)\n        return x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare DataLoader\ntrain_dataset = CustomDataset(train_data, tokenizer, MAX_LEN)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n\ntest_dataset = CustomDataset(test_data, tokenizer, MAX_LEN)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize classifier\nnum_labels = 4\nclassifier = Classifier(input_dim=model.config.hidden_size, hidden_dim=64, output_dim=num_labels)\n\n# Move classifier to GPU\nclassifier.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define loss function and optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(classifier.parameters(), lr=LEARNING_RATE, weight_decay=0.01)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n\n# Training loop\nfor epoch in range(EPOCHS):\n    # Train\n    classifier.train()\n    train_loss = 0.0\n    for batch in train_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        \n        optimizer.zero_grad()\n        \n        with torch.no_grad():\n            outputs = model(input_ids, attention_mask=attention_mask)\n            last_hidden_states = outputs.last_hidden_state[:, 0, :]  # CLS token\n\n        logits = classifier(last_hidden_states)\n        loss = loss_fn(logits, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item() * input_ids.size(0)\n\n    # Evaluate\n    classifier.eval()\n    val_loss = 0.0\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for batch in test_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            \n            outputs = model(input_ids, attention_mask=attention_mask)\n            last_hidden_states = outputs.last_hidden_state[:, 0, :]\n            \n            logits = classifier(last_hidden_states)\n            loss = loss_fn(logits, labels)\n            val_loss += loss.item() * input_ids.size(0)\n            \n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n\n    # Calculate metrics\n    train_loss /= len(train_data)\n    val_loss /= len(test_data)\n    report = classification_report(all_labels, all_preds)\n\n    # Calculate Accuracy\n    accuracy = accuracy_score(all_labels, all_preds)\n\n    # Calculate Macro F1\n    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n\n    # Calculate precision and recall for each label\n    precision_per_label = precision_score(all_labels, all_preds, average=None)\n    recall_per_label = recall_score(all_labels, all_preds, average=None)\n\n    print(f'Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n    print(f\"Accuracy for BERT: {accuracy:.4f}\")\n    print(\"Precision, Recall, F1-score for each label for BERT:\")\n    for label, precision, recall in zip(range(num_labels), precision_per_label, recall_per_label):\n        print(f\"Label {label}:\")\n        print(f\"  Precision: {precision:.4f}\")\n        print(f\"  Recall: {recall:.4f}\")\n        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n        print(f\"  F1-score: {f1:.4f}\")\n    print(f\"Macro F1-score for BERT: {macro_f1:.4f}\")\n    print('------------------------------------------------------------------------')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}